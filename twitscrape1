#london 11-12

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '51.509865, -0.118092, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-11 until:2022-3-12 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('London 11-12 March Associated Words')
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()

#london 12-13

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '51.509865, -0.118092, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-12 until:2022-3-13 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('London 12-13 March Associated Words')
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()


#london 13-14

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '51.509865, -0.118092, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-13 until:2022-3-14 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('London 13-14 March Associated Words', fontsize=20)
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()


#Manchester 11-12

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '53.483959, -2.244644, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-11 until:2022-3-12 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('Manchester 11-12 March Associated Words')
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()

#Manchester 12-13

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '53.483959, -2.244644, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-12 until:2022-3-13 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('Manchester 12-13 March Associated Words')
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()

#Manchester 13-14

import nltk

nltk.download('punkt')
nltk.download('wordnet')
from nltk import sent_tokenize, word_tokenize
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import stopwords
import pandas as pd
import numpy as np
import re  
import spacy
nlp = spacy.load('en_core_web_lg')

import pandas as pd
import snscrape.modules.twitter as sntwitter
import itertools

loc = '53.483959, -2.244644, 20km'
df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(
    'ukrainian geocode:"{}"'.format(loc) + ' since:2022-3-13 until:2022-3-14 lang:"en" ').get_items(), 1000))[['date', 'content']]

df=df_coord['content']

all_sentences = []

for word in df:
    all_sentences.append(word)

all_sentences

lines = list()
for line in all_sentences:    
    words = line.split()
    for w in words: 
       lines.append(w)

lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]

lines

lines2 = []

for word in lines:
    if word != '':
        lines2.append(word)

from nltk.stem.snowball import SnowballStemmer

s_stemmer = SnowballStemmer(language='english')

stem = []
for word in lines2:
    stem.append(s_stemmer.stem(word))
    
stem
stem2 = []

for word in stem:
    if word not in nlp.Defaults.stop_words:
        stem2.append(word)

stem2
df = pd.DataFrame(stem2)

df = df[0].value_counts()

from nltk.probability import FreqDist

freqdoctor = FreqDist()

for words in df:
    freqdoctor[words] += 1

freqdoctor

import matplotlib.pyplot as plt; plt.rcdefaults()
plt.rcParams.update({'font.size': 22})

df = df[:10,]
plt.figure(figsize=(10,5))
sns.barplot(df.values, df.index, alpha=0.8)
plt.title('Manchester 13-14 March Associated Words')
plt.ylabel('Word from Tweet')
plt.xlabel('Count of Words')
plt.show()
